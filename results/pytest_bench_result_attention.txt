-------------------------------------------------------------------------------------------------------------- benchmark: 10 tests ---------------------------------------------------------------------------------------------------------------
Name (time in us)                                                    Min                   Max                  Mean                StdDev                Median                IQR            Outliers          OPS            Rounds  Iterations
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
test_attention_fp8_e5m2_acc_fp32_tiled_feather_gpu[512-512]      13.4860 (1.0)        137.2570 (2.30)       109.0736 (3.75)        36.5922 (4.04)       123.1170 (5.84)      0.8835 (1.73)    1161;1264   9,168.1194 (0.27)       8932           1
test_attention_fp8_e5m2_acc_fp32_tiled_feather_gpu[512-4096]     13.5940 (1.01)     6,687.1140 (112.14)   5,501.0611 (189.32)   2,099.6193 (231.74)   6,299.8940 (298.66)   24.2152 (47.30)   1024;1427     181.7831 (0.01)       8013           1
test_attention_fp8_e5m2_acc_fp32_tiled_feather_gpu[512-256]      13.6520 (1.01)        59.6310 (1.0)         35.0188 (1.21)         9.0601 (1.0)         39.0160 (1.85)      0.5120 (1.0)     1679;1815  28,556.1179 (0.83)       9899           1
test_attention_fp8_e5m2_acc_fp32_tiled_feather_gpu[512-1024]     13.6730 (1.01)       503.3210 (8.44)       383.9229 (13.21)      130.7785 (14.43)      429.6965 (20.37)     3.7400 (7.30)    1059;1277   2,604.6893 (0.08)       9510           1
test_attention_fp8_e5m2_acc_fp32_tiled_feather_gpu[512-128]      17.7800 (1.32)       103.9340 (1.74)        38.4650 (1.32)        36.9187 (4.07)        21.0940 (1.0)      29.7817 (58.17)         1;1  25,997.6604 (0.76)          5           1
test_attention_fp32_torch[512-256]                               21.2780 (1.58)       189.6070 (3.18)        74.8339 (2.58)        14.5196 (1.60)        81.1430 (3.85)     11.7940 (23.04)     348;312  13,362.9291 (0.39)       5105           1
test_attention_fp32_torch[512-128]                               21.5140 (1.60)       126.6110 (2.12)        29.0565 (1.0)         26.0854 (2.88)        21.7245 (1.03)      1.0185 (1.99)          1;3  34,415.7077 (1.0)          16           1
test_attention_fp32_torch[512-1024]                              21.7960 (1.62)       763.5790 (12.81)      586.0291 (20.17)      155.7188 (17.19)      626.4730 (29.70)     7.9417 (15.51)     178;410   1,706.4000 (0.05)       2493           1
test_attention_fp32_torch[512-512]                               22.8460 (1.69)       289.2260 (4.85)       147.2141 (5.07)        30.3592 (3.35)       155.1090 (7.35)      1.1900 (2.32)      223;622   6,792.8267 (0.20)       3506           1
test_attention_fp32_torch[512-4096]                              22.9000 (1.70)     8,737.1300 (146.52)   7,622.5123 (262.33)   2,417.6176 (266.84)   8,390.5320 (397.77)   63.9538 (124.91)    204;215     131.1903 (0.00)       2221           1
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------